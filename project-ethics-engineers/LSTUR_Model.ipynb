{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Getting the Data + Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (Behaviors Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impression ID</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>History</th>\n",
       "      <th>Impressions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U13740</td>\n",
       "      <td>2019-11-11 09:05:58</td>\n",
       "      <td>[N55189, N42782, N34694, N45794, N18445, N6330...</td>\n",
       "      <td>[N55689-1, N35729-0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U91836</td>\n",
       "      <td>2019-11-12 18:11:30</td>\n",
       "      <td>[N31739, N6072, N63045, N23979, N35656, N43353...</td>\n",
       "      <td>[N20678-0, N39317-0, N58114-0, N20495-0, N4297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>U73700</td>\n",
       "      <td>2019-11-14 07:01:48</td>\n",
       "      <td>[N10732, N25792, N7563, N21087, N41087, N5445,...</td>\n",
       "      <td>[N50014-0, N23877-0, N35389-0, N49712-0, N1684...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U34670</td>\n",
       "      <td>2019-11-11 05:28:05</td>\n",
       "      <td>[N45729, N2203, N871, N53880, N41375, N43142, ...</td>\n",
       "      <td>[N35729-0, N33632-0, N49685-1, N27581-0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>U8125</td>\n",
       "      <td>2019-11-12 16:11:21</td>\n",
       "      <td>[N10078, N56514, N14904, N33740]</td>\n",
       "      <td>[N39985-0, N36050-0, N16096-0, N8400-1, N22407...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Impression ID User ID                Time  \\\n",
       "0              1  U13740 2019-11-11 09:05:58   \n",
       "1              2  U91836 2019-11-12 18:11:30   \n",
       "2              3  U73700 2019-11-14 07:01:48   \n",
       "3              4  U34670 2019-11-11 05:28:05   \n",
       "4              5   U8125 2019-11-12 16:11:21   \n",
       "\n",
       "                                             History  \\\n",
       "0  [N55189, N42782, N34694, N45794, N18445, N6330...   \n",
       "1  [N31739, N6072, N63045, N23979, N35656, N43353...   \n",
       "2  [N10732, N25792, N7563, N21087, N41087, N5445,...   \n",
       "3  [N45729, N2203, N871, N53880, N41375, N43142, ...   \n",
       "4                   [N10078, N56514, N14904, N33740]   \n",
       "\n",
       "                                         Impressions  \n",
       "0                               [N55689-1, N35729-0]  \n",
       "1  [N20678-0, N39317-0, N58114-0, N20495-0, N4297...  \n",
       "2  [N50014-0, N23877-0, N35389-0, N49712-0, N1684...  \n",
       "3           [N35729-0, N33632-0, N49685-1, N27581-0]  \n",
       "4  [N39985-0, N36050-0, N16096-0, N8400-1, N22407...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure History & Impressions is stored as a list\n",
    "column_names = ['Impression ID', 'User ID', 'Time', 'History', 'Impressions']\n",
    "behaviors_df = pd.read_csv(\"MINDsmall_train/behaviors.tsv\", sep='\\t', names=column_names)\n",
    "behaviors_df['History'] = behaviors_df['History'].str.split(' ')\n",
    "behaviors_df['Impressions'] = behaviors_df['Impressions'].str.split(' ')\n",
    "\n",
    "behaviors_df['Time'] = pd.to_datetime(behaviors_df['Time'])\n",
    "\n",
    "behaviors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (News Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title Entities</th>\n",
       "      <th>Abstract Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55528</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N19639</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N61837</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N53526</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AACk2N6.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"National Basketball Association\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N38324</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "      <td>They seem harmless, but there's a very good re...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAAKEkt.html</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  News ID   Category      SubCategory  \\\n",
       "0  N55528  lifestyle  lifestyleroyals   \n",
       "1  N19639     health       weightloss   \n",
       "2  N61837       news        newsworld   \n",
       "3  N53526     health           voices   \n",
       "4  N38324     health          medical   \n",
       "\n",
       "                                               Title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1                      50 Worst Habits For Belly Fat   \n",
       "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "4  How to Get Rid of Skin Tags, According to a De...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  These seemingly harmless habits are holding yo...   \n",
       "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "3  I felt like I was a fraud, and being an NBA wi...   \n",
       "4  They seem harmless, but there's a very good re...   \n",
       "\n",
       "                                             URL  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
       "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
       "\n",
       "                                      Title Entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
       "\n",
       "                                   Abstract Entities  \n",
       "0                                                 []  \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
       "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
       "3  [{\"Label\": \"National Basketball Association\", ...  \n",
       "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_column_names = ['News ID', 'Category', 'SubCategory', 'Title', 'Abstract','URL','Title Entities','Abstract Entities']\n",
    "news_df = pd.read_csv(\"MINDsmall_train/news.tsv\", sep='\\t',names=news_column_names)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Both Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behaviors_df columns: Index(['User ID', 'Time', 'News_ID', 'Impressions'], dtype='object')\n",
      "news_df columns: Index(['News_ID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL',\n",
      "       'Title Entities', 'Abstract Entities'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = ['Impression ID', 'User ID', 'Time', 'History', 'Impressions',]\n",
    "behaviors_df = pd.read_csv(\"MINDsmall_train/behaviors.tsv\", sep='\\t', names=column_names)\n",
    "behaviors_df = behaviors_df.drop(columns=[\"Impression ID\"])\n",
    "\n",
    "behaviors_df['History'] = behaviors_df['History'].str.split(' ')\n",
    "behaviors_df = behaviors_df.explode('History').rename(columns={'History': 'News_ID'})\n",
    "\n",
    "\n",
    "news_column_names = ['News_ID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'Title Entities', 'Abstract Entities']\n",
    "news_df = pd.read_csv(\"MINDsmall_train/news.tsv\", sep='\\t', names=news_column_names)\n",
    "\n",
    "merged_df = behaviors_df.merge(news_df, on='News_ID', how='left')\n",
    "merged_df = merged_df.drop_duplicates(subset=[\"User ID\",'News_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>News_ID</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Category_y</th>\n",
       "      <th>SubCategory_y</th>\n",
       "      <th>Title_y</th>\n",
       "      <th>Abstract_y</th>\n",
       "      <th>URL_y</th>\n",
       "      <th>Title Entities_y</th>\n",
       "      <th>Abstract Entities_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55689</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Charles Rogers, former Michigan State football...</td>\n",
       "      <td>Charles Rogers, the former Michigan State foot...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWAPO6.html</td>\n",
       "      <td>[{\"Label\": \"Charles Rogers (American football)...</td>\n",
       "      <td>[{\"Label\": \"2003 NFL Draft\", \"Type\": \"U\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N35729</td>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>Porsche launches into second story of New Jers...</td>\n",
       "      <td>The Porsche went airborne off a median in Toms...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWyjM9.html</td>\n",
       "      <td>[{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...</td>\n",
       "      <td>[{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55689</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Charles Rogers, former Michigan State football...</td>\n",
       "      <td>Charles Rogers, the former Michigan State foot...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWAPO6.html</td>\n",
       "      <td>[{\"Label\": \"Charles Rogers (American football)...</td>\n",
       "      <td>[{\"Label\": \"2003 NFL Draft\", \"Type\": \"U\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N35729</td>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>Porsche launches into second story of New Jers...</td>\n",
       "      <td>The Porsche went airborne off a median in Toms...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWyjM9.html</td>\n",
       "      <td>[{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...</td>\n",
       "      <td>[{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55689</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Charles Rogers, former Michigan State football...</td>\n",
       "      <td>Charles Rogers, the former Michigan State foot...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWAPO6.html</td>\n",
       "      <td>[{\"Label\": \"Charles Rogers (American football)...</td>\n",
       "      <td>[{\"Label\": \"2003 NFL Draft\", \"Type\": \"U\", \"Wik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User ID                   Time News_ID Impressions Category_y SubCategory_y  \\\n",
       "0  U13740  11/11/2019 9:05:58 AM  N55689           1     sports  football_nfl   \n",
       "1  U13740  11/11/2019 9:05:58 AM  N35729           0       news        newsus   \n",
       "2  U13740  11/11/2019 9:05:58 AM  N55689           1     sports  football_nfl   \n",
       "3  U13740  11/11/2019 9:05:58 AM  N35729           0       news        newsus   \n",
       "4  U13740  11/11/2019 9:05:58 AM  N55689           1     sports  football_nfl   \n",
       "\n",
       "                                             Title_y  \\\n",
       "0  Charles Rogers, former Michigan State football...   \n",
       "1  Porsche launches into second story of New Jers...   \n",
       "2  Charles Rogers, former Michigan State football...   \n",
       "3  Porsche launches into second story of New Jers...   \n",
       "4  Charles Rogers, former Michigan State football...   \n",
       "\n",
       "                                          Abstract_y  \\\n",
       "0  Charles Rogers, the former Michigan State foot...   \n",
       "1  The Porsche went airborne off a median in Toms...   \n",
       "2  Charles Rogers, the former Michigan State foot...   \n",
       "3  The Porsche went airborne off a median in Toms...   \n",
       "4  Charles Rogers, the former Michigan State foot...   \n",
       "\n",
       "                                           URL_y  \\\n",
       "0  https://assets.msn.com/labs/mind/BBWAPO6.html   \n",
       "1  https://assets.msn.com/labs/mind/BBWyjM9.html   \n",
       "2  https://assets.msn.com/labs/mind/BBWAPO6.html   \n",
       "3  https://assets.msn.com/labs/mind/BBWyjM9.html   \n",
       "4  https://assets.msn.com/labs/mind/BBWAPO6.html   \n",
       "\n",
       "                                    Title Entities_y  \\\n",
       "0  [{\"Label\": \"Charles Rogers (American football)...   \n",
       "1  [{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...   \n",
       "2  [{\"Label\": \"Charles Rogers (American football)...   \n",
       "3  [{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...   \n",
       "4  [{\"Label\": \"Charles Rogers (American football)...   \n",
       "\n",
       "                                 Abstract Entities_y  \n",
       "0  [{\"Label\": \"2003 NFL Draft\", \"Type\": \"U\", \"Wik...  \n",
       "1  [{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...  \n",
       "2  [{\"Label\": \"2003 NFL Draft\", \"Type\": \"U\", \"Wik...  \n",
       "3  [{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...  \n",
       "4  [{\"Label\": \"2003 NFL Draft\", \"Type\": \"U\", \"Wik...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yxt = merged_df.assign(Impressions=merged_df['Impressions'].str.split()).explode('Impressions')\n",
    "yxt['News_ID'] = yxt['Impressions'].str.split('-').str[0]\n",
    "yxt['Impressions'] = yxt['Impressions'].str.split('-').str[1]\n",
    "\n",
    "\n",
    "LSTUR_Model_df = yxt.merge(news_df, on='News_ID', how='left')\n",
    "LSTUR_Model_df = LSTUR_Model_df.loc[:, ~LSTUR_Model_df.columns.str.endswith('_x')]\n",
    "LSTUR_Model_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null History Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>News_ID</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Category_y</th>\n",
       "      <th>SubCategory_y</th>\n",
       "      <th>Title_y</th>\n",
       "      <th>Abstract_y</th>\n",
       "      <th>URL_y</th>\n",
       "      <th>Title Entities_y</th>\n",
       "      <th>Abstract Entities_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U33207</td>\n",
       "      <td>11/11/2019 11:09:14 AM</td>\n",
       "      <td>N62212</td>\n",
       "      <td>0</td>\n",
       "      <td>travel</td>\n",
       "      <td>travelnews</td>\n",
       "      <td>The world's first hybrid cruise ship is curren...</td>\n",
       "      <td>The MS Roald Amundsen's maiden voyage is a pol...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWvNny.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"MS Roald Amundsen\", \"Type\": \"V\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U33207</td>\n",
       "      <td>11/11/2019 11:09:14 AM</td>\n",
       "      <td>N27521</td>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Bolivian Leader Evo Morales Steps Down</td>\n",
       "      <td>President Evo Morales of Bolivia, who came to ...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWyw2S.html</td>\n",
       "      <td>[{\"Label\": \"Evo Morales\", \"Type\": \"P\", \"Wikida...</td>\n",
       "      <td>[{\"Label\": \"Evo Morales\", \"Type\": \"P\", \"Wikida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U33207</td>\n",
       "      <td>11/11/2019 11:09:14 AM</td>\n",
       "      <td>N28983</td>\n",
       "      <td>0</td>\n",
       "      <td>tv</td>\n",
       "      <td>tv-gallery</td>\n",
       "      <td>ICYMI: The week in TV news for Nov. 3-9</td>\n",
       "      <td>DWTS judge frustrated with Sean Spicer's run, ...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWtoek.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Donald Trump Jr.\", \"Type\": \"P\", \"W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U33207</td>\n",
       "      <td>11/11/2019 11:09:14 AM</td>\n",
       "      <td>N12028</td>\n",
       "      <td>0</td>\n",
       "      <td>finance</td>\n",
       "      <td>markets</td>\n",
       "      <td>Frackers Prepare to Pull Back, Exacerbating a ...</td>\n",
       "      <td>After pushing U.S. oil and natural-gas product...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWAqCG.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U33207</td>\n",
       "      <td>11/11/2019 11:09:14 AM</td>\n",
       "      <td>N25437</td>\n",
       "      <td>0</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>Is it really easier for men to lose weight? Ex...</td>\n",
       "      <td>There are reasons men and women lose weight di...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWtVz8.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User ID                    Time News_ID Impressions Category_y  \\\n",
       "0  U33207  11/11/2019 11:09:14 AM  N62212           0     travel   \n",
       "1  U33207  11/11/2019 11:09:14 AM  N27521           0       news   \n",
       "2  U33207  11/11/2019 11:09:14 AM  N28983           0         tv   \n",
       "3  U33207  11/11/2019 11:09:14 AM  N12028           0    finance   \n",
       "4  U33207  11/11/2019 11:09:14 AM  N25437           0     health   \n",
       "\n",
       "  SubCategory_y                                            Title_y  \\\n",
       "0    travelnews  The world's first hybrid cruise ship is curren...   \n",
       "1     newsworld             Bolivian Leader Evo Morales Steps Down   \n",
       "2    tv-gallery            ICYMI: The week in TV news for Nov. 3-9   \n",
       "3       markets  Frackers Prepare to Pull Back, Exacerbating a ...   \n",
       "4    weightloss  Is it really easier for men to lose weight? Ex...   \n",
       "\n",
       "                                          Abstract_y  \\\n",
       "0  The MS Roald Amundsen's maiden voyage is a pol...   \n",
       "1  President Evo Morales of Bolivia, who came to ...   \n",
       "2  DWTS judge frustrated with Sean Spicer's run, ...   \n",
       "3  After pushing U.S. oil and natural-gas product...   \n",
       "4  There are reasons men and women lose weight di...   \n",
       "\n",
       "                                           URL_y  \\\n",
       "0  https://assets.msn.com/labs/mind/BBWvNny.html   \n",
       "1  https://assets.msn.com/labs/mind/BBWyw2S.html   \n",
       "2  https://assets.msn.com/labs/mind/BBWtoek.html   \n",
       "3  https://assets.msn.com/labs/mind/BBWAqCG.html   \n",
       "4  https://assets.msn.com/labs/mind/BBWtVz8.html   \n",
       "\n",
       "                                    Title Entities_y  \\\n",
       "0                                                 []   \n",
       "1  [{\"Label\": \"Evo Morales\", \"Type\": \"P\", \"Wikida...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                 Abstract Entities_y  \n",
       "0  [{\"Label\": \"MS Roald Amundsen\", \"Type\": \"V\", \"...  \n",
       "1  [{\"Label\": \"Evo Morales\", \"Type\": \"P\", \"Wikida...  \n",
       "2  [{\"Label\": \"Donald Trump Jr.\", \"Type\": \"P\", \"W...  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nan_df = merged_df[merged_df[\"News_ID\"].isna()]\n",
    "Nan_df\n",
    "\n",
    "\n",
    "Nan_df1 = Nan_df.assign(Impressions=Nan_df['Impressions'].str.split()).explode('Impressions')\n",
    "Nan_df1.head(5)\n",
    "\n",
    "\n",
    "Nan_df1['News_ID'] = Nan_df1['Impressions'].str.split('-').str[0]\n",
    "Nan_df1['Impressions'] = Nan_df1['Impressions'].str.split('-').str[1]\n",
    "\n",
    "\n",
    "merged_null_df = Nan_df1.merge(news_df, on='News_ID', how='left')\n",
    "\n",
    "merged_null_df = merged_null_df.loc[:, ~merged_null_df.columns.str.endswith('_x')]\n",
    "merged_null_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Preparing all-user Data for Modeling: category+subcategory+Title predictors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([22951538, 19325508, 21089993, 17024087, 33598591, 35050156, 16435973,\n",
      "       14651967, 27128755, 19947706,\n",
      "       ...\n",
      "       21249687,  9628519, 31632483, 23981428, 29210711, 26301898, 26735830,\n",
      "       35788921, 13315092, 21081788],\n",
      "      dtype='int64', length=30249328)\n",
      "Index(['User ID', 'News_ID', 'Impressions', 'Category_y', 'SubCategory_y',\n",
      "       'Title_y'],\n",
      "      dtype='object')\n",
      "0\n",
      "['1' '0']\n"
     ]
    }
   ],
   "source": [
    "# Drop unwanted columns\n",
    "LSTUR_Model_df = LSTUR_Model_df.drop(\n",
    "    columns=['URL_y', 'Title Entities_y', 'Abstract Entities_y', 'Abstract_y', 'Time'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Label Encoding for String Columns\n",
    "label_encoders = {}\n",
    "for col in ['User ID', 'News_ID', 'Category_y', 'SubCategory_y', 'Title_y']:\n",
    "    le = LabelEncoder()\n",
    "    LSTUR_Model_df[col] = le.fit_transform(LSTUR_Model_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "\n",
    "LSTUR_Model_df.reset_index(drop=True, inplace=True)\n",
    "train_data, test_data = train_test_split(LSTUR_Model_df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#print(train_data.index)\n",
    "#print(train_data.columns)\n",
    "\n",
    "\n",
    "#print(train_data['Impressions'].isnull().sum()) \n",
    "#print(train_data['Impressions'].unique())       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impressions\n",
      "0    1271639\n",
      "1    1271639\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_majority = train_data[train_data['Impressions'] == '0']\n",
    "train_minority = train_data[train_data['Impressions'] == '1']\n",
    "\n",
    "\n",
    "train_majority_downsampled = resample(\n",
    "    train_majority,\n",
    "    replace=False, \n",
    "    n_samples=len(train_minority),  \n",
    "    random_state=42 \n",
    ")\n",
    "\n",
    "balanced_train_data = pd.concat([train_majority_downsampled, train_minority])\n",
    "balanced_train_data = balanced_train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#print(balanced_train_data['Impressions'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impressions\n",
      "0    1271639\n",
      "1    1271639\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_0 = train_data[train_data['Impressions'] == 0]\n",
    "class_1 = train_data[train_data['Impressions'] == 1]\n",
    "\n",
    "\n",
    "class_0_downsampled = resample(\n",
    "    class_0,\n",
    "    replace=False,  \n",
    "    n_samples=len(class_1),  \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "train_data_balanced = pd.concat([class_0_downsampled, class_1])\n",
    "train_data_balanced = train_data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#print(train_data_balanced['Impressions'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User_ID': tensor([18383, 12624, 24537, 17028, 43940, 10991, 45361, 28360, 39470, 20871,\n",
      "        29215, 35692, 41570, 45558, 47880, 32609, 35548, 46725, 36571, 15429,\n",
      "        27646, 47954, 27223, 34444, 13684, 13906,   501, 31581,  5801, 21256,\n",
      "        31126,  2621, 43627, 43745, 42118, 27500, 40348, 38238,  9469, 36826,\n",
      "        27840, 11582, 14316, 31352, 23787,  4678, 36224, 46253, 29896, 14840,\n",
      "        21866,  1306, 16000, 47330, 15695, 42966, 44857,  6411, 19166,  3183,\n",
      "        47890, 43520, 17768,  1040]), 'News_ID': tensor([ 1938, 12611,  3823,  7994,  3641,  1178, 12603, 14066,  7147, 13805,\n",
      "        15164,  9773,  7744,  2646,  9770, 10338,  1250,  7148, 10208, 11235,\n",
      "         4911,  4254,  2780,  5958, 10338,  4621, 15274,  7013,  3647,  8241,\n",
      "        10344,  1110,  1001, 12467, 10451, 12979,  6161, 10333,  4424, 12430,\n",
      "         7499, 11050,  7588, 15150, 13773,  7353,  6398,  8270, 15075, 11155,\n",
      "         8013, 15464, 11892,  8596, 15485, 14981,  7724, 15365,  3384,  5591,\n",
      "        15164,  4563,  3194,   530]), 'Category': tensor([ 6,  9,  9,  9, 12,  9,  9, 11, 11,  8, 12, 11,  6,  6, 11,  9, 12,  2,\n",
      "         2, 11,  9, 12,  9,  3,  9, 11,  4,  3,  6,  9, 11,  2, 12,  9,  1, 11,\n",
      "        13,  9,  1, 11,  6,  9,  6,  2,  1,  4,  4,  6, 11,  9, 11,  9, 11, 13,\n",
      "        11,  9, 12, 11,  9,  1, 12,  9,  1,  6]), 'SubCategory': tensor([107, 143, 147, 147, 183, 147, 149,  75,  75, 127, 197,  75,  91, 200,\n",
      "         25, 135, 183,  60,  59,  75, 147, 184, 143, 178, 135,  75, 205,  72,\n",
      "        110, 135,  86,  62, 183, 143,  46,  79, 188, 145,  38,  75, 200, 135,\n",
      "         94,  67,  85, 152, 117,  96,  27,  43,  75,  43,  75, 189,  75, 147,\n",
      "        183,  75, 139,  38, 197, 138,  38, 108]), 'Title': tensor([ 8217,  1898,  2829,  9462,  4927,  8274, 14388,  2512,   308, 11758,\n",
      "        13424,  9189,  4470,  9058, 13566,  3576, 13355, 12705,   455,  7317,\n",
      "         5033, 13839,  6945,  6461,  3576,  9184, 11675, 10542, 10673,  5422,\n",
      "         3425,  1078, 12132,   266, 13156,  4052,  6047,  4903,  7712,  3378,\n",
      "         6776,   374,   849,  1327,  5622,  1099, 11840,  1345,  7074, 11029,\n",
      "         7031,  2180,  9925,  3194,  3034,  5446, 12886, 10114,  1481, 13010,\n",
      "        13424, 10811,  7382, 15226]), 'Impressions': tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "# Define a custom PyTorch Dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'User_ID': torch.tensor(row['User ID'], dtype=torch.long),\n",
    "            'News_ID': torch.tensor(row['News_ID'], dtype=torch.long),\n",
    "            'Category': torch.tensor(row['Category_y'], dtype=torch.long),\n",
    "            'SubCategory': torch.tensor(row['SubCategory_y'], dtype=torch.long),\n",
    "            'Title': torch.tensor(row['Title_y'], dtype=torch.long),\n",
    "            'Impressions': torch.tensor(row['Impressions'], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "\n",
    "dataset = NewsDataset(train_data_balanced)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "#print(batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTUR(\n",
       "  (user_embedding): Embedding(50000, 128)\n",
       "  (news_embedding): Embedding(50000, 128)\n",
       "  (attention): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (project): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (rnn): GRU(64, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTUR(nn.Module):\n",
    "    def __init__(self, embedding_dim, attention_dim, hidden_dim):\n",
    "        super(LSTUR, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=50000, embedding_dim=embedding_dim)\n",
    "        self.news_embedding = nn.Embedding(num_embeddings=50000, embedding_dim=embedding_dim)\n",
    "        self.attention = nn.Linear(embedding_dim, attention_dim)\n",
    "        self.project = nn.Linear(embedding_dim, attention_dim)  # Project embedding_dim to attention_dim\n",
    "        self.rnn = nn.GRU(input_size=attention_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_ids, news_ids, categories, subcategories, titles):\n",
    "        user_emb = self.user_embedding(user_ids).unsqueeze(1)\n",
    "        news_emb = self.news_embedding(news_ids).unsqueeze(1)\n",
    "        cat_emb = self.news_embedding(categories).unsqueeze(1)\n",
    "        subcat_emb = self.news_embedding(subcategories).unsqueeze(1)\n",
    "        title_emb = self.news_embedding(titles).unsqueeze(1)\n",
    "\n",
    "        # embedding\n",
    "        combined_emb = torch.cat((user_emb, news_emb, cat_emb, subcat_emb, title_emb), dim=1)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = self.attention(combined_emb)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        attn_output = torch.matmul(attn_weights.transpose(1, 2), combined_emb)\n",
    "\n",
    "        # Project the output to attention_dim\n",
    "        attn_output = self.project(attn_output)\n",
    "\n",
    "        # GRU for sequential learning\n",
    "        rnn_output, _ = self.rnn(attn_output)\n",
    "\n",
    "        # Fully connected layer for final prediction\n",
    "        logits = self.fc(rnn_output[:, -1, :])\n",
    "        outputs = self.sigmoid(logits)\n",
    "        return outputs\n",
    "\n",
    "# Initialize model\n",
    "embedding_dim = 128\n",
    "attention_dim = 64\n",
    "hidden_dim = 128\n",
    "model = LSTUR(embedding_dim, attention_dim, hidden_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/1: 100%|██████████| 39739/39739 [31:37<00:00, 20.94batch/s, loss=0.68] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.6815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Training Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "        for batch in train_loader:\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            titles = batch['Title'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, news_ids, categories, subcategories, titles)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.squeeze(), impressions)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to lstur_model 1 (Full).pth\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the model\n",
    "model_save_path = \"lstur_model 1 (Full).pth\"\n",
    "\n",
    "# Save the model state dictionary\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "#print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/3xbqy_ss7d12n5z58vw1xq2r0000gn/T/ipykernel_56155/2462728791.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_path = \"lstur_model 1 (Full).pth\"\n",
    "loaded_model = LSTUR(embedding_dim=128, attention_dim=64, hidden_dim=128)\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval() \n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataset for cleaning\n",
    "train_data_cleaned = train_data.copy()\n",
    "test_data_cleaned = test_data.copy()\n",
    "\n",
    "# Clean 'Impressions' column in train and test data\n",
    "train_data_cleaned['Impressions'] = pd.to_numeric(train_data_cleaned['Impressions'], errors='coerce')\n",
    "test_data_cleaned['Impressions'] = pd.to_numeric(test_data_cleaned['Impressions'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid 'Impressions' values\n",
    "train_data_cleaned = train_data_cleaned[train_data_cleaned['Impressions'].isin([0, 1])]\n",
    "test_data_cleaned = test_data_cleaned[test_data_cleaned['Impressions'].isin([0, 1])]\n",
    "\n",
    "# Reset index \n",
    "train_data_cleaned = train_data_cleaned.reset_index(drop=True)\n",
    "test_data_cleaned = test_data_cleaned.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'User_ID': torch.tensor(row['User ID'], dtype=torch.long),\n",
    "            'News_ID': torch.tensor(row['News_ID'], dtype=torch.long),\n",
    "            'Category': torch.tensor(row['Category_y'], dtype=torch.long),\n",
    "            'SubCategory': torch.tensor(row['SubCategory_y'], dtype=torch.long),\n",
    "            'Title': torch.tensor(row['Title_y'], dtype=torch.long),\n",
    "            'Impressions': torch.tensor(float(row['Impressions']), dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and dataloader\n",
    "test_dataset = NewsDataset(test_data_cleaned)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating AUC: 100%|██████████| 236323/236323 [26:57<00:00, 146.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5965\n"
     ]
    }
   ],
   "source": [
    "#calculating auc\n",
    "def calculate_auc(model, data_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Calculating AUC\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            titles = batch['Title'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories, titles).squeeze().cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(predictions)\n",
    "            all_labels.extend(impressions.cpu().numpy())\n",
    "\n",
    "    auc_score = roc_auc_score(all_labels, all_preds)\n",
    "    return auc_score\n",
    "\n",
    "\n",
    "auc = calculate_auc(loaded_model, test_loader)\n",
    "#print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR: 100%|██████████| 236323/236323 [28:09<00:00, 139.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#calculating mrr\n",
    "def calculate_mrr(model, data_loader):\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Calculating MRR\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            titles = batch['Title'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories, titles).squeeze().cpu().numpy()\n",
    "\n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            sorted_impressions = impressions.cpu().numpy()[sorted_indices]\n",
    "\n",
    "            for i, label in enumerate(sorted_impressions):\n",
    "                if label == 1: \n",
    "                    all_scores.append(1 / (i + 1))\n",
    "                    break\n",
    "            else:\n",
    "                all_scores.append(0)\n",
    "\n",
    "    return np.mean(all_scores)\n",
    "\n",
    "\n",
    "mrr = calculate_mrr(loaded_model, test_loader)\n",
    "#print(f\"MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating nDCG@5: 100%|██████████| 236323/236323 [26:41<00:00, 147.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@5: 0.1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating nDCG@10: 100%|██████████| 236323/236323 [28:06<00:00, 140.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@10: 0.1967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#calculating ndcg@5 and ndcg@10\n",
    "def calculate_ndcg(model, data_loader, k):\n",
    "    model.eval()\n",
    "    all_ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(data_loader, desc=f\"Calculating nDCG@{k}\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            titles = batch['Title'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories, titles).squeeze().cpu().numpy()\n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            sorted_impressions = impressions.cpu().numpy()[sorted_indices]\n",
    "\n",
    "            dcg = sum(\n",
    "                (sorted_impressions[i] / np.log2(i + 2)) for i in range(min(len(sorted_impressions), k))\n",
    "            )\n",
    "            ideal_sorted = sorted(sorted_impressions, reverse=True)\n",
    "            ideal_dcg = sum(\n",
    "                (ideal_sorted[i] / np.log2(i + 2)) for i in range(min(len(ideal_sorted), k))\n",
    "            )\n",
    "            ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "            all_ndcg_scores.append(ndcg)\n",
    "\n",
    "    return np.mean(all_ndcg_scores)\n",
    "\n",
    "ndcg_5 = calculate_ndcg(loaded_model, test_loader, k=5)\n",
    "#print(f\"nDCG@5: {ndcg_5:.4f}\")\n",
    "\n",
    "ndcg_10 = calculate_ndcg(loaded_model, test_loader, k=10)\n",
    "#print(f\"nDCG@10: {ndcg_10:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Preparing No history user Data for Modeling: category+subcategory+Title predictors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([24136, 29756, 11733, 26562,  2955, 10890, 11903, 19352, 31144,  7671,\n",
      "       ...\n",
      "        2433,   769,  1685, 16023, 21962, 16850,  6265, 11284,   860, 15795],\n",
      "      dtype='int64', length=26896)\n",
      "Index(['User ID', 'News_ID', 'Impressions', 'Category_y', 'SubCategory_y',\n",
      "       'Title_y'],\n",
      "      dtype='object')\n",
      "0\n",
      "['0' '1']\n"
     ]
    }
   ],
   "source": [
    "LSTUR_Model_NAN_1 = merged_null_df.drop(\n",
    "    columns=['URL_y', 'Title Entities_y', 'Abstract Entities_y', 'Abstract_y', 'Time'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Label Encoding for String Columns\n",
    "label_encoders = {}\n",
    "for col in ['User ID', 'News_ID', 'Category_y', 'SubCategory_y', 'Title_y']:\n",
    "    le = LabelEncoder()\n",
    "    LSTUR_Model_NAN_1[col] = le.fit_transform(LSTUR_Model_NAN_1[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "LSTUR_Model_NAN_1.reset_index(drop=True, inplace=True)\n",
    "train_data, test_data = train_test_split(LSTUR_Model_NAN_1, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#print(train_data.index)\n",
    "#print(train_data.columns)\n",
    "\n",
    "#print(train_data['Impressions'].isnull().sum())  \n",
    "#print(train_data['Impressions'].unique())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "[0 1]\n",
      "Number of samples in the majority class: 25856\n",
      "Number of samples in the minority class: 1040\n",
      "Balanced dataset class distribution:\n",
      "Impressions\n",
      "1    1040\n",
      "0    1040\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data['Impressions'] = pd.to_numeric(train_data['Impressions'], errors='coerce')\n",
    "\n",
    "\n",
    "#print(train_data['Impressions'].dtype)  \n",
    "#print(train_data['Impressions'].unique())  \n",
    "\n",
    "train_data = train_data.dropna(subset=['Impressions'])\n",
    "train_majority = train_data[train_data['Impressions'] == 0]\n",
    "train_minority = train_data[train_data['Impressions'] == 1]\n",
    "\n",
    "\n",
    "#print(\"Number of samples in the majority class:\", len(train_majority))\n",
    "#print(\"Number of samples in the minority class:\", len(train_minority))\n",
    "\n",
    "\n",
    "if train_minority.empty:\n",
    "    raise ValueError(\"The minority class is empty, and resampling cannot proceed.\")\n",
    "\n",
    "#sampling\n",
    "train_majority_downsampled = resample(\n",
    "    train_majority,\n",
    "    replace=False,  \n",
    "    n_samples=len(train_minority),  \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "balanced_train_data = pd.concat([train_majority_downsampled, train_minority])\n",
    "balanced_train_data = balanced_train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verify the balance of the dataset\n",
    "#print(\"Balanced dataset class distribution:\")\n",
    "#print(balanced_train_data['Impressions'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User_ID': tensor([ 61, 127, 177, 378, 101, 557, 219, 623, 438, 588, 614, 377, 773, 219,\n",
      "        187, 527, 787,  93, 274, 773, 227, 376, 366, 238, 811, 492, 820, 421,\n",
      "         25, 728, 678, 818, 831, 239, 494, 422, 243, 341, 771, 720, 229, 466,\n",
      "        216, 875, 809, 708, 247, 594, 126, 767, 394, 794, 613,  14, 644, 522,\n",
      "        112,  36, 819, 811, 333, 199, 578, 724]), 'News_ID': tensor([1146, 1900, 1600, 2804, 3688, 1099, 1728, 1502, 2025,  796,  238, 1692,\n",
      "        3650, 3203, 2731, 1516, 1446, 2180, 1741,  879,  571, 2734, 3592, 3262,\n",
      "         476, 2676, 1060, 2908,  211, 2934, 2097, 2406, 2741, 2779, 3269, 2560,\n",
      "        3694,  390, 3302, 3110,  401, 3203, 1535, 3728, 2057, 2567, 2057, 3642,\n",
      "        2044, 2406, 1802,  773, 3223,  256, 2534, 1205, 2057, 1182,   63, 2509,\n",
      "        1520,  209, 1522, 2325]), 'Category': tensor([ 9,  3,  9,  2,  2,  8,  0,  2,  5,  8,  7,  9,  8,  1,  2,  7,  4,  5,\n",
      "         8, 11, 11, 10,  8, 10,  2,  8,  8,  1,  8, 13,  7,  5,  8,  4,  4,  5,\n",
      "         2, 10,  8,  0,  9,  1,  9,  2, 11,  7, 11, 13,  8,  5,  3,  4,  7,  8,\n",
      "         8,  8, 11,  8,  3,  9,  4, 13, 11,  8]), 'SubCategory': tensor([ 60, 129,  61,  52,  92, 117,  15,  92,  77, 114, 106,  23, 121,  31,\n",
      "         92,  32, 165,  73, 123, 155, 152, 148, 123, 146,  92,  33, 113,  31,\n",
      "        110, 163, 103, 135, 110, 165,   0,  87,  47, 144, 110,   6,  60,  31,\n",
      "         58,  92, 152, 106, 152, 163, 117, 135,  57,  65, 103, 110, 123, 123,\n",
      "        152, 121, 131,  60,  94, 163, 151, 114]), 'Title': tensor([1932, 2191, 1234,  779, 2503, 2540, 1590,  429,  375,  457, 1296, 3578,\n",
      "        1875,  893, 3166, 3312, 1254, 1147,  784, 1066,  134, 3154, 2799, 1769,\n",
      "        2131, 2601, 2553, 1634, 1309, 2345,  493,  123,  272, 3698, 2303, 3701,\n",
      "        1789, 3720, 2657,  235, 1500,  893, 1333, 2874,  866,  813,  866,  983,\n",
      "        1401,  123,  142, 1152, 2750,  856, 2237, 1574,  866,   15,  391, 3744,\n",
      "        2791, 3137, 2949, 1671]), 'Impressions': tensor([1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "# Define a custom PyTorch Dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'User_ID': torch.tensor(row['User ID'], dtype=torch.long),\n",
    "            'News_ID': torch.tensor(row['News_ID'], dtype=torch.long),\n",
    "            'Category': torch.tensor(row['Category_y'], dtype=torch.long),\n",
    "            'SubCategory': torch.tensor(row['SubCategory_y'], dtype=torch.long),\n",
    "            'Title': torch.tensor(row['Title_y'], dtype=torch.long),\n",
    "            'Impressions': torch.tensor(row['Impressions'], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "dataset = NewsDataset(balanced_train_data)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "#print(batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTUR(\n",
       "  (user_embedding): Embedding(50000, 128)\n",
       "  (news_embedding): Embedding(50000, 128)\n",
       "  (attention): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (project): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (rnn): GRU(64, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTUR(nn.Module):\n",
    "    def __init__(self, embedding_dim, attention_dim, hidden_dim):\n",
    "        super(LSTUR, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=50000, embedding_dim=embedding_dim)\n",
    "        self.news_embedding = nn.Embedding(num_embeddings=50000, embedding_dim=embedding_dim)\n",
    "        self.attention = nn.Linear(embedding_dim, attention_dim)\n",
    "        self.project = nn.Linear(embedding_dim, attention_dim)  \n",
    "        self.rnn = nn.GRU(input_size=attention_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_ids, news_ids, categories, subcategories, titles):\n",
    "        # Embedding layers\n",
    "        user_emb = self.user_embedding(user_ids).unsqueeze(1)\n",
    "        news_emb = self.news_embedding(news_ids).unsqueeze(1)\n",
    "        cat_emb = self.news_embedding(categories).unsqueeze(1)\n",
    "        subcat_emb = self.news_embedding(subcategories).unsqueeze(1)\n",
    "        title_emb = self.news_embedding(titles).unsqueeze(1)\n",
    "\n",
    "        # Combine embeddings\n",
    "        combined_emb = torch.cat((user_emb, news_emb, cat_emb, subcat_emb, title_emb), dim=1)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = self.attention(combined_emb)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        attn_output = torch.matmul(attn_weights.transpose(1, 2), combined_emb)\n",
    "\n",
    "        # Project the output to attention_dim\n",
    "        attn_output = self.project(attn_output)\n",
    "\n",
    "        # GRU for sequential learning\n",
    "        rnn_output, _ = self.rnn(attn_output)\n",
    "\n",
    "        # Fully connected layer for final prediction\n",
    "        logits = self.fc(rnn_output[:, -1, :])\n",
    "        outputs = self.sigmoid(logits)\n",
    "        return outputs\n",
    "\n",
    "# Initialize model\n",
    "embedding_dim = 128\n",
    "attention_dim = 64\n",
    "hidden_dim = 128\n",
    "model = LSTUR(embedding_dim, attention_dim, hidden_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/1: 100%|██████████| 33/33 [00:01<00:00, 24.40batch/s, loss=0.659]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Training Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "        for batch in train_loader:\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            titles = batch['Title'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, news_ids, categories, subcategories, titles)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.squeeze(), impressions)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to lstur_model 1 (NAN).pth\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the model\n",
    "\n",
    "#model_save_path = \"lstur_model 1 (NAN).pth\"\n",
    "#torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/3xbqy_ss7d12n5z58vw1xq2r0000gn/T/ipykernel_1151/1865632766.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"lstur_model 1 (NAN).pth\"\n",
    "loaded_model = LSTUR(embedding_dim=128, attention_dim=64, hidden_dim=128)\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()  #\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned successfully!\n"
     ]
    }
   ],
   "source": [
    "#cleaning data/reset index\n",
    "train_data_cleaned = train_data.copy()\n",
    "test_data_cleaned = test_data.copy()\n",
    "\n",
    "train_data_cleaned['Impressions'] = pd.to_numeric(train_data_cleaned['Impressions'], errors='coerce')\n",
    "test_data_cleaned['Impressions'] = pd.to_numeric(test_data_cleaned['Impressions'], errors='coerce')\n",
    "train_data_cleaned = train_data_cleaned[train_data_cleaned['Impressions'].isin([0, 1])]\n",
    "test_data_cleaned = test_data_cleaned[test_data_cleaned['Impressions'].isin([0, 1])]\n",
    "\n",
    "train_data_cleaned = train_data_cleaned.reset_index(drop=True)\n",
    "test_data_cleaned = test_data_cleaned.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'User_ID': torch.tensor(row['User ID'], dtype=torch.long),\n",
    "            'News_ID': torch.tensor(row['News_ID'], dtype=torch.long),\n",
    "            'Category': torch.tensor(row['Category_y'], dtype=torch.long),\n",
    "            'SubCategory': torch.tensor(row['SubCategory_y'], dtype=torch.long),\n",
    "            'Title': torch.tensor(row['Title_y'], dtype=torch.long),\n",
    "            'Impressions': torch.tensor(float(row['Impressions']), dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and dataloader\n",
    "test_dataset = NewsDataset(test_data_cleaned)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating AUC: 100%|██████████| 211/211 [00:01<00:00, 169.65batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_auc(model, data_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add a loading bar to the data loader\n",
    "        for batch in tqdm(data_loader, desc=\"Calculating AUC\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            titles = batch['Title'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories, titles).squeeze().cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(predictions)\n",
    "            all_labels.extend(impressions.cpu().numpy())\n",
    "\n",
    "    auc_score = roc_auc_score(all_labels, all_preds)\n",
    "    return auc_score\n",
    "\n",
    "# Calculate AUC with a loading bar\n",
    "auc = calculate_auc(loaded_model, test_loader)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR: 100%|██████████| 211/211 [00:01<00:00, 158.04batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_mrr(model, data_loader):\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add a loading bar to the data loader\n",
    "        for batch in tqdm(data_loader, desc=\"Calculating MRR\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            titles = batch['Title'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories, titles).squeeze().cpu().numpy()\n",
    "\n",
    "            # Sort predictions \n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            sorted_impressions = impressions.cpu().numpy()[sorted_indices]\n",
    "\n",
    "            # Calculate reciprocal rank for  bataches\n",
    "            for i, label in enumerate(sorted_impressions):\n",
    "                if label == 1:  \n",
    "                    all_scores.append(1 / (i + 1))\n",
    "                    break\n",
    "            else:\n",
    "                all_scores.append(0)\n",
    "\n",
    "    return np.mean(all_scores)\n",
    "\n",
    "mrr = calculate_mrr(loaded_model, test_loader)\n",
    "#print(f\"MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating nDCG@5: 100%|██████████| 211/211 [00:01<00:00, 165.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@5: 0.1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating nDCG@10: 100%|██████████| 211/211 [00:01<00:00, 170.72batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@10: 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_ndcg(model, data_loader, k):\n",
    "    model.eval()\n",
    "    all_ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add a loading bar to the data loader\n",
    "        for batch in tqdm(data_loader, desc=f\"Calculating nDCG@{k}\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            titles = batch['Title'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories, titles).squeeze().cpu().numpy()\n",
    "\n",
    "            # Sort predictions and calculate nDCG\n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            sorted_impressions = impressions.cpu().numpy()[sorted_indices]\n",
    "\n",
    "            dcg = sum(\n",
    "                (sorted_impressions[i] / np.log2(i + 2)) for i in range(min(len(sorted_impressions), k))\n",
    "            )\n",
    "            ideal_sorted = sorted(sorted_impressions, reverse=True)\n",
    "            ideal_dcg = sum(\n",
    "                (ideal_sorted[i] / np.log2(i + 2)) for i in range(min(len(ideal_sorted), k))\n",
    "            )\n",
    "            ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "            all_ndcg_scores.append(ndcg)\n",
    "\n",
    "    return np.mean(all_ndcg_scores)\n",
    "\n",
    "\n",
    "ndcg_5 = calculate_ndcg(loaded_model, test_loader, k=5)\n",
    "print(f\"nDCG@5: {ndcg_5:.4f}\")\n",
    "\n",
    "ndcg_10 = calculate_ndcg(loaded_model, test_loader, k=10)\n",
    "print(f\"nDCG@10: {ndcg_10:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Preparing all-user Data for Modeling: category+subcategory predictors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([22951538, 19325508, 21089993, 17024087, 33598591, 35050156, 16435973,\n",
      "       14651967, 27128755, 19947706,\n",
      "       ...\n",
      "       21249687,  9628519, 31632483, 23981428, 29210711, 26301898, 26735830,\n",
      "       35788921, 13315092, 21081788],\n",
      "      dtype='int64', length=30249328)\n",
      "Index(['User ID', 'News_ID', 'Impressions', 'Category_y', 'SubCategory_y'], dtype='object')\n",
      "0\n",
      "['1' '0']\n"
     ]
    }
   ],
   "source": [
    "LSTUR_Model_df_2 = LSTUR_Model_df.drop(\n",
    "    columns=['URL_y', 'Title Entities_y', 'Abstract Entities_y', 'Abstract_y', 'Time', 'Title_y'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "label_encoders = {}\n",
    "for col in ['User ID', 'News_ID', 'Category_y', 'SubCategory_y']:\n",
    "    le = LabelEncoder()\n",
    "    LSTUR_Model_df_2[col] = le.fit_transform(LSTUR_Model_df_2[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Reset indices\n",
    "LSTUR_Model_df_2.reset_index(drop=True, inplace=True)\n",
    "# Train-test split\n",
    "train_data, test_data = train_test_split(LSTUR_Model_df_2, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#print(train_data.index)\n",
    "#print(train_data.columns)\n",
    "\n",
    "#print(train_data['Impressions'].isnull().sum())  \n",
    "#print(train_data['Impressions'].unique())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impressions\n",
      "0.0    1271639\n",
      "1.0    1271639\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_majority = train_data[train_data['Impressions'] == 0]\n",
    "train_minority = train_data[train_data['Impressions'] == 1]\n",
    "\n",
    "# Downsample \n",
    "train_majority_downsampled = resample(\n",
    "    train_majority,\n",
    "    replace=False,  \n",
    "    n_samples=len(train_minority),  \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "balanced_train_data = pd.concat([train_majority_downsampled, train_minority])\n",
    "balanced_train_data = balanced_train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#print(balanced_train_data['Impressions'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User_ID': tensor([29325, 16903, 45476, 49202,   569, 49059, 15570, 47950, 22663, 27871,\n",
      "        45964, 21471,   936,  2309, 32536, 19056,  9501, 27286,  8909, 47401,\n",
      "        23564, 27812, 32237, 11018, 38308, 44488, 44087, 38524,  6847, 34279,\n",
      "        49312, 43147, 38179, 13589, 48482,  8430,  3589,  1043, 13118,  4228,\n",
      "        38772, 13470, 33626, 14991, 30931, 34027,  3338, 24978, 42294, 17701,\n",
      "        36541,  3366,  2565, 41188,  2623, 34836, 16264, 12465, 14529, 24688,\n",
      "        12021,  5664, 46916, 29591]), 'News_ID': tensor([14733,  9371,  1135, 13695,  6546,  6398, 13161, 10085,  2602, 15036,\n",
      "         9093, 12657,  8743,  8741,    34,  4448,  5086, 14825, 10866,  4293,\n",
      "        14623,  5086,  6000,  6562, 14307,  8270, 10874, 15468, 10874,  9858,\n",
      "         8657,  6753, 10447,  3537,  6398, 15375, 11653,  3986,  2960, 10085,\n",
      "         9619,  6435,  5497,  3680,  6171, 13573,  4453,  9944,  7569,  4325,\n",
      "        13434,  5885,  5272,  7871,  5211,  3094, 13539, 11469,  6000,  4788,\n",
      "         8728,  1110,   948,  4550]), 'Category': tensor([ 2,  6,  6, 12,  6,  4,  2, 14, 12,  3,  6,  9,  8, 11,  2,  1,  9,  3,\n",
      "         4,  9,  6,  9,  9,  6, 11,  6,  9, 11,  9,  9,  2, 14, 11,  3,  4, 11,\n",
      "        13,  1,  3, 14,  1,  9,  2,  6, 14,  9,  9,  2, 13,  8,  1,  6,  9,  9,\n",
      "        12,  0,  7,  9,  9, 11, 13,  2,  9,  6]), 'SubCategory': tensor([ 53,  91,  91, 183,  91, 117,  53,   3, 196, 160,  91, 147, 127,  73,\n",
      "         53,  46, 135,  72, 152, 135, 110, 135, 147,  92,  25,  96, 143,  75,\n",
      "        143, 143,  53, 158,  75,  72, 117,  75, 195,  46,  72,   3,  85, 147,\n",
      "         65,  90, 199, 147, 143,  53, 189, 131,  38, 200, 147, 147, 183,  12,\n",
      "        120, 149, 147,  75, 188,  62, 145,  97]), 'Impressions': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "# train_data['Impressions'] = train_data['Impressions'].astype(float)\n",
    "\n",
    "# Define a custom PyTorch Dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'User_ID': torch.tensor(row['User ID'], dtype=torch.long),\n",
    "            'News_ID': torch.tensor(row['News_ID'], dtype=torch.long),\n",
    "            'Category': torch.tensor(row['Category_y'], dtype=torch.long),\n",
    "            'SubCategory': torch.tensor(row['SubCategory_y'], dtype=torch.long),\n",
    "            'Impressions': torch.tensor(row['Impressions'], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create PyTorch Dataset and DataLoader\n",
    "dataset = NewsDataset(balanced_train_data)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Check data loader\n",
    "batch = next(iter(train_loader))\n",
    "#print(batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTUR(\n",
       "  (user_embedding): Embedding(50000, 128)\n",
       "  (news_embedding): Embedding(50000, 128)\n",
       "  (attention): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (project): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (rnn): GRU(64, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTUR(nn.Module):\n",
    "    def __init__(self, embedding_dim, attention_dim, hidden_dim):\n",
    "        super(LSTUR, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=50000, embedding_dim=embedding_dim)\n",
    "        self.news_embedding = nn.Embedding(num_embeddings=50000, embedding_dim=embedding_dim)\n",
    "        self.attention = nn.Linear(embedding_dim, attention_dim)\n",
    "        self.project = nn.Linear(embedding_dim, attention_dim)  # Project embedding_dim to attention_dim\n",
    "        self.rnn = nn.GRU(input_size=attention_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_ids, news_ids, categories, subcategories):\n",
    "        # Embedding layers\n",
    "        user_emb = self.user_embedding(user_ids).unsqueeze(1)\n",
    "        news_emb = self.news_embedding(news_ids).unsqueeze(1)\n",
    "        cat_emb = self.news_embedding(categories).unsqueeze(1)\n",
    "        subcat_emb = self.news_embedding(subcategories).unsqueeze(1)\n",
    "\n",
    "        # Combine embeddings\n",
    "        combined_emb = torch.cat((user_emb, news_emb, cat_emb, subcat_emb), dim=1)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = self.attention(combined_emb)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        attn_output = torch.matmul(attn_weights.transpose(1, 2), combined_emb)\n",
    "\n",
    "        # Project the output to attention_dim\n",
    "        attn_output = self.project(attn_output)\n",
    "\n",
    "        # GRU for sequential learning\n",
    "        rnn_output, _ = self.rnn(attn_output)\n",
    "\n",
    "        # Fully connected layer for final prediction\n",
    "        logits = self.fc(rnn_output[:, -1, :])\n",
    "        outputs = self.sigmoid(logits)\n",
    "        return outputs\n",
    "\n",
    "embedding_dim = 128\n",
    "attention_dim = 64\n",
    "hidden_dim = 128\n",
    "model = LSTUR(embedding_dim, attention_dim, hidden_dim)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/1: 100%|██████████| 39739/39739 [25:43<00:00, 25.74batch/s, loss=0.706]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Training Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "        for batch in train_loader:\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, news_ids, categories, subcategories)\n",
    "\n",
    "            loss = criterion(outputs.squeeze(), impressions)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to lstur_model 2 (Full).pth\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the model\n",
    "\n",
    "#model_save_path = \"lstur_model 2 (Full).pth\"\n",
    "#torch.save(model.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/3xbqy_ss7d12n5z58vw1xq2r0000gn/T/ipykernel_1151/1551488654.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_path = \"lstur_model 2 (Full).pth\"\n",
    "loaded_model = LSTUR(embedding_dim=128, attention_dim=64, hidden_dim=128)\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()  \n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned successfully!\n"
     ]
    }
   ],
   "source": [
    "#cleaning/reset index\n",
    "train_data_cleaned = train_data.copy()\n",
    "test_data_cleaned = test_data.copy()\n",
    "\n",
    "\n",
    "train_data_cleaned['Impressions'] = pd.to_numeric(train_data_cleaned['Impressions'], errors='coerce')\n",
    "test_data_cleaned['Impressions'] = pd.to_numeric(test_data_cleaned['Impressions'], errors='coerce')\n",
    "\n",
    "train_data_cleaned = train_data_cleaned[train_data_cleaned['Impressions'].isin([0, 1])]\n",
    "test_data_cleaned = test_data_cleaned[test_data_cleaned['Impressions'].isin([0, 1])]\n",
    "\n",
    "\n",
    "train_data_cleaned = train_data_cleaned.reset_index(drop=True)\n",
    "test_data_cleaned = test_data_cleaned.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'User_ID': torch.tensor(row['User ID'], dtype=torch.long),\n",
    "            'News_ID': torch.tensor(row['News_ID'], dtype=torch.long),\n",
    "            'Category': torch.tensor(row['Category_y'], dtype=torch.long),\n",
    "            'SubCategory': torch.tensor(row['SubCategory_y'], dtype=torch.long),\n",
    "            'Impressions': torch.tensor(float(row['Impressions']), dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and dataloader\n",
    "test_dataset = NewsDataset(test_data_cleaned)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating AUC: 100%|██████████| 236323/236323 [22:57<00:00, 171.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5772\n"
     ]
    }
   ],
   "source": [
    "def calculate_auc(model, data_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Calculating AUC\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories).squeeze().cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(predictions)\n",
    "            all_labels.extend(impressions.cpu().numpy())\n",
    "\n",
    "    auc_score = roc_auc_score(all_labels, all_preds)\n",
    "    return auc_score\n",
    "\n",
    "# Calculate AUC \n",
    "auc = calculate_auc(loaded_model, test_loader)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR: 100%|██████████| 236323/236323 [23:37<00:00, 166.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.2151\n"
     ]
    }
   ],
   "source": [
    "def calculate_mrr(model, data_loader):\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add a loading bar to the data loader\n",
    "        for batch in tqdm(data_loader, desc=\"Calculating MRR\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories).squeeze().cpu().numpy()\n",
    "\n",
    "            # Sort predictions\n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            sorted_impressions = impressions.cpu().numpy()[sorted_indices]\n",
    "\n",
    "            # Calculate reciprocal rank for each batch\n",
    "            for i, label in enumerate(sorted_impressions):\n",
    "                if label == 1: \n",
    "                    all_scores.append(1 / (i + 1))\n",
    "                    break\n",
    "            else:\n",
    "                all_scores.append(0)\n",
    "\n",
    "    return np.mean(all_scores)\n",
    "\n",
    "# Calculate MRR \n",
    "mrr = calculate_mrr(loaded_model, test_loader)\n",
    "print(f\"MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating nDCG@5: 100%|██████████| 236323/236323 [23:23<00:00, 168.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@5: 0.1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating nDCG@10: 100%|██████████| 236323/236323 [22:39<00:00, 173.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@10: 0.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_ndcg(model, data_loader, k):\n",
    "    model.eval()\n",
    "    all_ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add a loading bar to the data loader\n",
    "        for batch in tqdm(data_loader, desc=f\"Calculating nDCG@{k}\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories).squeeze().cpu().numpy()\n",
    "\n",
    "            # Sort predictions and calculate nDCG\n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            sorted_impressions = impressions.cpu().numpy()[sorted_indices]\n",
    "\n",
    "            dcg = sum(\n",
    "                (sorted_impressions[i] / np.log2(i + 2)) for i in range(min(len(sorted_impressions), k))\n",
    "            )\n",
    "            ideal_sorted = sorted(sorted_impressions, reverse=True)\n",
    "            ideal_dcg = sum(\n",
    "                (ideal_sorted[i] / np.log2(i + 2)) for i in range(min(len(ideal_sorted), k))\n",
    "            )\n",
    "            ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "            all_ndcg_scores.append(ndcg)\n",
    "\n",
    "    return np.mean(all_ndcg_scores)\n",
    "\n",
    "# Calculate nDCG@5 and nDCG@10 \n",
    "ndcg_5 = calculate_ndcg(loaded_model, test_loader, k=5)\n",
    "print(f\"nDCG@5: {ndcg_5:.4f}\")\n",
    "\n",
    "ndcg_10 = calculate_ndcg(loaded_model, test_loader, k=10)\n",
    "print(f\"nDCG@10: {ndcg_10:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Preparing no historu user Data for Modeling: category+subcategory predictors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([24136, 29756, 11733, 26562,  2955, 10890, 11903, 19352, 31144,  7671,\n",
      "       ...\n",
      "        2433,   769,  1685, 16023, 21962, 16850,  6265, 11284,   860, 15795],\n",
      "      dtype='int64', length=26896)\n",
      "Index(['User ID', 'News_ID', 'Impressions', 'Category_y', 'SubCategory_y'], dtype='object')\n",
      "0\n",
      "['0' '1']\n"
     ]
    }
   ],
   "source": [
    "LSTUR_Model_NAN_2 = merged_null_df.drop(\n",
    "    columns=['URL_y', 'Title Entities_y', 'Abstract Entities_y', 'Abstract_y', 'Time', 'Title_y'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "label_encoders = {}\n",
    "for col in ['User ID', 'News_ID', 'Category_y', 'SubCategory_y']:\n",
    "    le = LabelEncoder()\n",
    "    LSTUR_Model_NAN_2[col] = le.fit_transform(LSTUR_Model_NAN_2[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Reset indices for training data\n",
    "LSTUR_Model_NAN_2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Train-test split\n",
    "train_data, test_data = train_test_split(LSTUR_Model_NAN_2, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(train_data.index)\n",
    "#print(train_data.columns)\n",
    "\n",
    "\n",
    "#print(train_data['Impressions'].isnull().sum())  \n",
    "#print(train_data['Impressions'].unique())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "[0 1]\n",
      "Number of samples in the majority class: 25856\n",
      "Number of samples in the minority class: 1040\n",
      "Balanced dataset class distribution:\n",
      "Impressions\n",
      "1    1040\n",
      "0    1040\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data['Impressions'] = pd.to_numeric(train_data['Impressions'], errors='coerce')\n",
    "\n",
    "\n",
    "#print(train_data['Impressions'].dtype)  # Should now be int64 or float64\n",
    "#print(train_data['Impressions'].unique())  # Ensure it contains [0, 1] or expected values\n",
    "\n",
    "# Drop rows with NaN in 'Impressions' after conversion (if any)\n",
    "train_data = train_data.dropna(subset=['Impressions'])\n",
    "\n",
    "# Separate the majority and minority classes\n",
    "train_majority = train_data[train_data['Impressions'] == 0]\n",
    "train_minority = train_data[train_data['Impressions'] == 1]\n",
    "\n",
    "# Verify the separation\n",
    "print(\"Number of samples in the majority class:\", len(train_majority))\n",
    "print(\"Number of samples in the minority class:\", len(train_minority))\n",
    "\n",
    "# Ensure the minority class is not empty before proceeding\n",
    "if train_minority.empty:\n",
    "    raise ValueError(\"The minority class is empty, and resampling cannot proceed.\")\n",
    "\n",
    "# Downsample the majority class\n",
    "train_majority_downsampled = resample(\n",
    "    train_majority,\n",
    "    replace=False,  \n",
    "    n_samples=len(train_minority), \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "\n",
    "balanced_train_data = pd.concat([train_majority_downsampled, train_minority])\n",
    "balanced_train_data = balanced_train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verify the balance of the dataset\n",
    "#print(\"Balanced dataset class distribution:\")\n",
    "#print(balanced_train_data['Impressions'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User_ID': tensor([436, 314, 274, 516, 163, 792, 141,  75, 591, 186, 533, 582,  95, 554,\n",
      "        105, 332,  75, 249,  65, 502, 878, 705, 737, 290, 345, 121, 556, 341,\n",
      "        728, 490, 372, 717, 102, 386, 505, 212, 313, 728, 178, 389, 516, 393,\n",
      "        607, 537, 438,  90,  85, 281, 730, 746,  94, 110,  42, 644, 858, 462,\n",
      "        701, 675, 710, 249, 465, 659, 403, 590]), 'News_ID': tensor([1854, 2057, 2159, 1930, 1366, 3300, 2567,  214, 3556, 1915,  881,  858,\n",
      "        3142, 3407, 2685, 2640, 1769, 1055,  850, 3143, 2856,  157, 1769, 2534,\n",
      "        2397,   99, 1275, 3565, 2734, 1476, 1544, 1706, 1312,  350,  330, 2998,\n",
      "         532, 3345, 2998, 2594,  673, 2785,  326, 1735, 1400,  253, 3755, 1980,\n",
      "        3558,  689,  537, 1091,  162, 2534, 2557, 3226, 2399, 1125, 2097,  727,\n",
      "         705, 3476, 2123, 3719]), 'Category': tensor([ 9, 11,  8,  9, 10,  7,  7,  4,  9,  8,  8,  9,  2,  8, 10,  2,  4,  6,\n",
      "         5, 11,  8, 11,  4,  8,  8, 12,  3,  8, 10,  9,  9,  2,  8,  0,  6, 13,\n",
      "         0,  3, 13,  2, 13,  8,  4,  7,  5, 11,  0, 13,  2,  1,  8,  1,  6,  8,\n",
      "         8,  9,  3,  8,  7,  0,  2,  5,  8,  8]), 'SubCategory': tensor([ 60, 152, 121,  60, 146, 103, 106, 124,  21, 121, 110,  60,  41, 123,\n",
      "        148,  92, 124, 100,  87, 151, 117, 157, 124, 123, 121,   2,  57, 110,\n",
      "        148,  60,  61,  47, 123,   5,  97, 163,  10, 132, 163,  49, 163, 121,\n",
      "        165, 103, 162, 151,  10, 163,  41,  31, 123,  35,  99, 123, 121,  60,\n",
      "        132, 110, 103,   5,  41,  87, 121, 110]), 'Impressions': tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 1., 0.])}\n"
     ]
    }
   ],
   "source": [
    "# Define a custom PyTorch Dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'User_ID': torch.tensor(row['User ID'], dtype=torch.long),\n",
    "            'News_ID': torch.tensor(row['News_ID'], dtype=torch.long),\n",
    "            'Category': torch.tensor(row['Category_y'], dtype=torch.long),\n",
    "            'SubCategory': torch.tensor(row['SubCategory_y'], dtype=torch.long),\n",
    "            'Impressions': torch.tensor(row['Impressions'], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create PyTorch Dataset and DataLoader\n",
    "dataset = NewsDataset(balanced_train_data)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Check data loader\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTUR(\n",
       "  (user_embedding): Embedding(50000, 128)\n",
       "  (news_embedding): Embedding(50000, 128)\n",
       "  (attention): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (project): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (rnn): GRU(64, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTUR(nn.Module):\n",
    "    def __init__(self, embedding_dim, attention_dim, hidden_dim):\n",
    "        super(LSTUR, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=50000, embedding_dim=embedding_dim)\n",
    "        self.news_embedding = nn.Embedding(num_embeddings=50000, embedding_dim=embedding_dim)\n",
    "        self.attention = nn.Linear(embedding_dim, attention_dim)\n",
    "        self.project = nn.Linear(embedding_dim, attention_dim)  # Project embedding_dim to attention_dim\n",
    "        self.rnn = nn.GRU(input_size=attention_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_ids, news_ids, categories, subcategories):\n",
    "        # Embedding layers\n",
    "        user_emb = self.user_embedding(user_ids).unsqueeze(1)\n",
    "        news_emb = self.news_embedding(news_ids).unsqueeze(1)\n",
    "        cat_emb = self.news_embedding(categories).unsqueeze(1)\n",
    "        subcat_emb = self.news_embedding(subcategories).unsqueeze(1)\n",
    "\n",
    "        # Combine embeddings\n",
    "        combined_emb = torch.cat((user_emb, news_emb, cat_emb, subcat_emb), dim=1)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = self.attention(combined_emb)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        attn_output = torch.matmul(attn_weights.transpose(1, 2), combined_emb)\n",
    "\n",
    "        # Project the output to attention_dim\n",
    "        attn_output = self.project(attn_output)\n",
    "\n",
    "        # GRU for sequential learning\n",
    "        rnn_output, _ = self.rnn(attn_output)\n",
    "\n",
    "        # Fully connected layer for final prediction\n",
    "        logits = self.fc(rnn_output[:, -1, :])\n",
    "        outputs = self.sigmoid(logits)\n",
    "        return outputs\n",
    "\n",
    "# Initialize model\n",
    "embedding_dim = 128\n",
    "attention_dim = 64\n",
    "hidden_dim = 128\n",
    "model = LSTUR(embedding_dim, attention_dim, hidden_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/1: 100%|██████████| 33/33 [00:01<00:00, 24.94batch/s, loss=0.669]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Training Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "        for batch in train_loader:\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, news_ids, categories, subcategories)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.squeeze(), impressions)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to lstur_model 2 (NAN).pth\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the model\n",
    "\n",
    "#model_save_path = \"lstur_model 2 (NAN).pth\"\n",
    "#torch.save(model.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/3xbqy_ss7d12n5z58vw1xq2r0000gn/T/ipykernel_1151/1176666411.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_path = \"lstur_model 2 (NAN).pth\"\n",
    "loaded_model = LSTUR(embedding_dim=128, attention_dim=64, hidden_dim=128)\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning/reset index\n",
    "train_data_cleaned = train_data.copy()\n",
    "test_data_cleaned = test_data.copy()\n",
    "\n",
    "train_data_cleaned['Impressions'] = pd.to_numeric(train_data_cleaned['Impressions'], errors='coerce')\n",
    "test_data_cleaned['Impressions'] = pd.to_numeric(test_data_cleaned['Impressions'], errors='coerce')\n",
    "train_data_cleaned = train_data_cleaned[train_data_cleaned['Impressions'].isin([0, 1])]\n",
    "test_data_cleaned = test_data_cleaned[test_data_cleaned['Impressions'].isin([0, 1])]\n",
    "\n",
    "\n",
    "train_data_cleaned = train_data_cleaned.reset_index(drop=True)\n",
    "test_data_cleaned = test_data_cleaned.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'User_ID': torch.tensor(row['User ID'], dtype=torch.long),\n",
    "            'News_ID': torch.tensor(row['News_ID'], dtype=torch.long),\n",
    "            'Category': torch.tensor(row['Category_y'], dtype=torch.long),\n",
    "            'SubCategory': torch.tensor(row['SubCategory_y'], dtype=torch.long),\n",
    "            'Impressions': torch.tensor(float(row['Impressions']), dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and dataloader\n",
    "test_dataset = NewsDataset(test_data_cleaned)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating AUC: 100%|██████████| 211/211 [00:01<00:00, 161.42batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_auc(model, data_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add a loading bar to the data loader\n",
    "        for batch in tqdm(data_loader, desc=\"Calculating AUC\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories).squeeze().cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(predictions)\n",
    "            all_labels.extend(impressions.cpu().numpy())\n",
    "\n",
    "    auc_score = roc_auc_score(all_labels, all_preds)\n",
    "    return auc_score\n",
    "\n",
    "# Calculate AUC \n",
    "auc = calculate_auc(loaded_model, test_loader)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR: 100%|██████████| 211/211 [00:01<00:00, 165.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_mrr(model, data_loader):\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add a loading bar to the data loader\n",
    "        for batch in tqdm(data_loader, desc=\"Calculating MRR\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories).squeeze().cpu().numpy()\n",
    "\n",
    "            # Sort predictions and calculate ranks\n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            sorted_impressions = impressions.cpu().numpy()[sorted_indices]\n",
    "\n",
    "            # Calculate reciprocal rank for each batch\n",
    "            for i, label in enumerate(sorted_impressions):\n",
    "                if label == 1:  \n",
    "                    all_scores.append(1 / (i + 1))\n",
    "                    break\n",
    "            else:\n",
    "                all_scores.append(0)\n",
    "\n",
    "    return np.mean(all_scores)\n",
    "\n",
    "# Calculate MRR \n",
    "mrr = calculate_mrr(loaded_model, test_loader)\n",
    "print(f\"MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating nDCG@5: 100%|██████████| 211/211 [00:01<00:00, 164.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@5: 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating nDCG@10: 100%|██████████| 211/211 [00:01<00:00, 165.14batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@10: 0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_ndcg(model, data_loader, k):\n",
    "    model.eval()\n",
    "    all_ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add a loading bar to the data loader\n",
    "        for batch in tqdm(data_loader, desc=f\"Calculating nDCG@{k}\", unit=\"batch\"):\n",
    "            user_ids = batch['User_ID'].to(device)\n",
    "            news_ids = batch['News_ID'].to(device)\n",
    "            categories = batch['Category'].to(device)\n",
    "            subcategories = batch['SubCategory'].to(device)\n",
    "            impressions = batch['Impressions'].to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(user_ids, news_ids, categories, subcategories).squeeze().cpu().numpy()\n",
    "\n",
    "            # Sort predictions and calculate nDCG\n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            sorted_impressions = impressions.cpu().numpy()[sorted_indices]\n",
    "\n",
    "            dcg = sum(\n",
    "                (sorted_impressions[i] / np.log2(i + 2)) for i in range(min(len(sorted_impressions), k))\n",
    "            )\n",
    "            ideal_sorted = sorted(sorted_impressions, reverse=True)\n",
    "            ideal_dcg = sum(\n",
    "                (ideal_sorted[i] / np.log2(i + 2)) for i in range(min(len(ideal_sorted), k))\n",
    "            )\n",
    "            ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "            all_ndcg_scores.append(ndcg)\n",
    "\n",
    "    return np.mean(all_ndcg_scores)\n",
    "\n",
    "# Calculate nDCG@5 and nDCG@10 with loading bars\n",
    "ndcg_5 = calculate_ndcg(loaded_model, test_loader, k=5)\n",
    "print(f\"nDCG@5: {ndcg_5:.4f}\")\n",
    "\n",
    "ndcg_10 = calculate_ndcg(loaded_model, test_loader, k=10)\n",
    "print(f\"nDCG@10: {ndcg_10:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
